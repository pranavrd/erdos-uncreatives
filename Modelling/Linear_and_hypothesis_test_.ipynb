{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "5vX0c4JOQYMp",
    "outputId": "8de64bd2-20af-4062-9b0f-b4dec05b1eae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rQlhGaw8QgYn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/new/no_early_dates_all_features_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FAzACGrQvwy",
    "outputId": "bc5ea4fd-e147-47eb-b65b-c045bff81074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'commentsCount', 'isChannelVerified', 'likes',\n",
       "       'numberOfSubscribers', 'text', 'title', 'viewCount',\n",
       "       'views_per_subscriber', 'duration_in_seconds', 'date',\n",
       "       'hashtag_indicator', 'has_any_affiliate', 'hasAdinTitle', 'hasAdinText',\n",
       "       'Engagement_per_Subscriber', 'Engagement_per_View', 'popular_brand',\n",
       "       'prime_hour', 'product', 'skills/teach', 'speed', 'comparing_products',\n",
       "       'self_ref', 'budget', 'korean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "smyHNMO3VAVn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"korean\", \"speed\", \"skills/teach\", \"comparing_products\", \"prime_hour\", \"hasAdinTitle\", \"hasAdinText\",'hashtag_indicator']\n",
    "\n",
    "#Create the target column $y$ here\n",
    "df[\"y\"] = (df[\"likes\"] + df[\"commentsCount\"])  / (df[\"viewCount\"] + 1)\n",
    "\n",
    "#get rid of noisy columns\n",
    "df = df[ features + [\"y\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JorvUfeNQv53",
    "outputId": "46ab5c78-c5a2-4352-e1b5-8a47a7fcdc0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration set: 3968 rows\n",
      "Confirmation set: 3969 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into exploration set and confirmation\n",
    "df_explore, df_confirm = train_test_split(df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Exploration set: {df_explore.shape[0]} rows\")\n",
    "print(f\"Confirmation set: {df_confirm.shape[0]} rows\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWWP9t0WQwAI",
    "outputId": "10e186c3-f06d-442f-c91d-9c7ed2c8c614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on real data:\n",
      "Linear model MSE: 0.000999\n",
      "Random Forest MSE: 0.000784\n",
      "Improvement ratio: 1.27x (how much better RF is than linear)\n",
      "\n",
      "Performance on simulated linear data:\n",
      "Linear model MSE: 0.000970\n",
      "Random Forest MSE: 0.000801\n",
      "Improvement ratio: 1.21x (how much better RF is than linear)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_explore_scaled = scaler.fit_transform(df_explore[features])\n",
    "\n",
    "pipe_linear = Pipeline([\n",
    "    (\"interaction_terms\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "])\n",
    "pipe_linear.fit(X_explore_scaled, df_explore[\"y\"])\n",
    "\n",
    "linear_pred = pipe_linear.predict(X_explore_scaled)\n",
    "linear_mse = mean_squared_error(df_explore[\"y\"], linear_pred)\n",
    "\n",
    "\n",
    "#RF\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_explore_scaled, df_explore[\"y\"])\n",
    "rf_pred = rf.predict(X_explore_scaled)\n",
    "rf_mse = mean_squared_error(df_explore[\"y\"], rf_pred)\n",
    "\n",
    "# Calculate performance ratio on real data\n",
    "real_ratio = linear_mse / rf_mse\n",
    "\n",
    "print(\"Performance on real data:\")\n",
    "print(f\"Linear model MSE: {linear_mse:.6f}\")\n",
    "print(f\"Random Forest MSE: {rf_mse:.6f}\")\n",
    "print(f\"Improvement ratio: {real_ratio:.2f}x (how much better RF is than linear)\")\n",
    "\n",
    "\n",
    "# Generate simulated data under hyphothesis 0\n",
    "residuals = df_explore[\"y\"] - linear_pred\n",
    "std_residuals = np.std(residuals)\n",
    "np.random.seed(42)\n",
    "y_simulated = linear_pred + np.random.normal(0, std_residuals, len(linear_pred))\n",
    "\n",
    "pipe_linear_sim = Pipeline([\n",
    "    (\"interaction_terms\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "])\n",
    "pipe_linear_sim.fit(X_explore_scaled, y_simulated)\n",
    "linear_sim_pred = pipe_linear_sim.predict(X_explore_scaled)\n",
    "linear_sim_mse = mean_squared_error(y_simulated, linear_sim_pred)\n",
    "\n",
    "rf_sim = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_sim.fit(X_explore_scaled, y_simulated)\n",
    "rf_sim_pred = rf_sim.predict(X_explore_scaled)\n",
    "rf_sim_mse = mean_squared_error(y_simulated, rf_sim_pred)\n",
    "\n",
    "sim_ratio = linear_sim_mse / rf_sim_mse\n",
    "\n",
    "print(\"\\nPerformance on simulated linear data:\")\n",
    "print(f\"Linear model MSE: {linear_sim_mse:.6f}\")\n",
    "print(f\"Random Forest MSE: {rf_sim_mse:.6f}\")\n",
    "print(f\"Improvement ratio: {sim_ratio:.2f}x (how much better RF is than linear)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XM09X92AQwDI",
    "outputId": "23eb76bd-6bcf-4b72-a388-fc71dbae423d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All non-zero features sorted by coefficient magnitude:\n",
      "skills/teach hasAdinText       -0.000013\n",
      "budget comparing_products      -0.000022\n",
      "prime_hour hasAdinTitle         0.000033\n",
      "prime_hour hashtag_indicator    0.000035\n",
      "popular_brand budget            0.000044\n",
      "                                  ...   \n",
      "prime_hour                      0.002429\n",
      "product hashtag_indicator       0.002747\n",
      "hashtag_indicator              -0.003010\n",
      "popular_brand skills/teach      0.003132\n",
      "popular_brand                  -0.003172\n",
      "Length: 75, dtype: float64\n",
      "\n",
      "Top 10 most important features:\n",
      "skills/teach                       0.001843\n",
      "self_ref                           0.001880\n",
      "popular_brand hashtag_indicator   -0.001995\n",
      "skills/teach hashtag_indicator    -0.002008\n",
      "self_ref speed                    -0.002370\n",
      "prime_hour                         0.002429\n",
      "product hashtag_indicator          0.002747\n",
      "hashtag_indicator                 -0.003010\n",
      "popular_brand skills/teach         0.003132\n",
      "popular_brand                     -0.003172\n",
      "dtype: float64\n",
      "\n",
      "Formulated hypotheses:\n",
      "1. Videos with 'skills/teach' increase engagement (coef=0.001843)\n",
      "2. Videos with 'self_ref' increase engagement (coef=0.001880)\n",
      "3. Videos that combine 'popular_brand' and 'hashtag_indicator' decrease engagement (coef=-0.001995)\n",
      "4. Videos that combine 'skills/teach' and 'hashtag_indicator' decrease engagement (coef=-0.002008)\n",
      "5. Videos that combine 'self_ref' and 'speed' decrease engagement (coef=-0.002370)\n",
      "6. Videos with 'prime_hour' increase engagement (coef=0.002429)\n",
      "7. Videos that combine 'product' and 'hashtag_indicator' increase engagement (coef=0.002747)\n",
      "8. Videos with 'hashtag_indicator' decrease engagement (coef=-0.003010)\n",
      "9. Videos that combine 'popular_brand' and 'skills/teach' increase engagement (coef=0.003132)\n",
      "10. Videos with 'popular_brand' decrease engagement (coef=-0.003172)\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients\n",
    "transformed_feature_names = pipe_linear.named_steps['interaction_terms'].get_feature_names_out(features)\n",
    "lasso_coeffs = pd.Series(\n",
    "    pipe_linear.named_steps['lasso'].coef_,\n",
    "    index=transformed_feature_names\n",
    ")\n",
    "\n",
    "# Get non-zero coefficients\n",
    "sig_lasso_coeffs = lasso_coeffs[lasso_coeffs != 0]\n",
    "important_features = sig_lasso_coeffs.sort_values(key=abs)\n",
    "\n",
    "print(\"\\nAll non-zero features sorted by coefficient magnitude:\")\n",
    "print(important_features)\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "top_features = important_features.tail(10)\n",
    "print(top_features)\n",
    "\n",
    "# create hypotheses\n",
    "hypotheses = []\n",
    "for feature, coef in top_features.items():\n",
    "    expected_direction = \"positive\" if coef > 0 else \"negative\"\n",
    "    impact = \"increase\" if coef > 0 else \"decrease\"\n",
    "\n",
    "    if \" \" in feature:\n",
    "        # For interaction terms\n",
    "        parts = feature.split(\" \")\n",
    "        hypothesis_text = f\"Videos that combine '{parts[0]}' and '{parts[1]}' {impact} engagement\"\n",
    "    else:\n",
    "        # For single features\n",
    "        hypothesis_text = f\"Videos with '{feature}' {impact} engagement\"\n",
    "\n",
    "    hypotheses.append({\n",
    "        \"feature\": feature,\n",
    "        \"coefficient\": coef,\n",
    "        \"expected_direction\": expected_direction,\n",
    "        \"hypothesis\": hypothesis_text\n",
    "    })\n",
    "\n",
    "print(\"\\nFormulated hypotheses:\")\n",
    "for i, hyp in enumerate(hypotheses, 1):\n",
    "    print(f\"{i}. {hyp['hypothesis']} (coef={hyp['coefficient']:.6f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBDxCjUKHRXt",
    "outputId": "dffa0f7b-e783-4d3f-faf3-f8c997b78479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['popular_brand', 'has_any_affiliate', 'product', 'budget', 'self_ref',\n",
       "       'korean', 'speed', 'skills/teach', 'comparing_products', 'prime_hour',\n",
       "       'hasAdinTitle', 'hasAdinText', 'hashtag_indicator', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confirm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iX4jl0T7C7z5",
    "outputId": "fd36ad7b-68aa-483a-b9c7-b3cef2c703b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'skills/teach',\n",
       "  'coefficient': 0.0018434095237098594,\n",
       "  'expected_direction': 'positive',\n",
       "  'hypothesis': \"Videos with 'skills/teach' increase engagement\"},\n",
       " {'feature': 'self_ref',\n",
       "  'coefficient': 0.0018799266533280502,\n",
       "  'expected_direction': 'positive',\n",
       "  'hypothesis': \"Videos with 'self_ref' increase engagement\"},\n",
       " {'feature': 'popular_brand hashtag_indicator',\n",
       "  'coefficient': -0.001995424822419821,\n",
       "  'expected_direction': 'negative',\n",
       "  'hypothesis': \"Videos that combine 'popular_brand' and 'hashtag_indicator' decrease engagement\"},\n",
       " {'feature': 'skills/teach hashtag_indicator',\n",
       "  'coefficient': -0.00200766036931156,\n",
       "  'expected_direction': 'negative',\n",
       "  'hypothesis': \"Videos that combine 'skills/teach' and 'hashtag_indicator' decrease engagement\"},\n",
       " {'feature': 'self_ref speed',\n",
       "  'coefficient': -0.0023700812120385465,\n",
       "  'expected_direction': 'negative',\n",
       "  'hypothesis': \"Videos that combine 'self_ref' and 'speed' decrease engagement\"},\n",
       " {'feature': 'prime_hour',\n",
       "  'coefficient': 0.0024293714883996693,\n",
       "  'expected_direction': 'positive',\n",
       "  'hypothesis': \"Videos with 'prime_hour' increase engagement\"},\n",
       " {'feature': 'product hashtag_indicator',\n",
       "  'coefficient': 0.002747104620766307,\n",
       "  'expected_direction': 'positive',\n",
       "  'hypothesis': \"Videos that combine 'product' and 'hashtag_indicator' increase engagement\"},\n",
       " {'feature': 'hashtag_indicator',\n",
       "  'coefficient': -0.003010465285334543,\n",
       "  'expected_direction': 'negative',\n",
       "  'hypothesis': \"Videos with 'hashtag_indicator' decrease engagement\"},\n",
       " {'feature': 'popular_brand skills/teach',\n",
       "  'coefficient': 0.0031320884209667934,\n",
       "  'expected_direction': 'positive',\n",
       "  'hypothesis': \"Videos that combine 'popular_brand' and 'skills/teach' increase engagement\"},\n",
       " {'feature': 'popular_brand',\n",
       "  'coefficient': -0.0031721336772260523,\n",
       "  'expected_direction': 'negative',\n",
       "  'hypothesis': \"Videos with 'popular_brand' decrease engagement\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-X_hRFq_d4sb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Test each hypothesis on the confirmation dataset\n",
    "results = []\n",
    "\n",
    "for hypothesis in hypotheses:\n",
    "    feature = hypothesis[\"feature\"]\n",
    "    expected_direction = hypothesis[\"expected_direction\"]\n",
    "\n",
    "    if \" \" not in feature:\n",
    "        if feature not in df_confirm.columns:\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hypothesis': hypothesis[\"hypothesis\"],\n",
    "                'result': \"Feature not found in dataset\",\n",
    "                'confirmed': False\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Group data based on feature presence\n",
    "        with_feature = df_confirm[df_confirm[feature] == 1][\"y\"]\n",
    "        without_feature = df_confirm[df_confirm[feature] == 0][\"y\"]\n",
    "\n",
    "        # Skip if either group is too small\n",
    "        if len(with_feature) < 10 or len(without_feature) < 10:\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hypothesis': hypothesis[\"hypothesis\"],\n",
    "                'result': f\"Insufficient data (with={len(with_feature)}, without={len(without_feature)})\",\n",
    "                'confirmed': False\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        #  t-test\n",
    "        t_stat, p_value = stats.ttest_ind(with_feature, without_feature, equal_var=False)\n",
    "\n",
    "        # Check if result confirms hypothesis direction\n",
    "        mean_diff = with_feature.mean() - without_feature.mean()\n",
    "        direction_confirmed = (\n",
    "            (expected_direction == \"positive\" and mean_diff > 0) or\n",
    "            (expected_direction == \"negative\" and mean_diff < 0)\n",
    "        )\n",
    "\n",
    "        # Record results\n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'hypothesis': hypothesis[\"hypothesis\"],\n",
    "            'mean_with': with_feature.mean(),\n",
    "            'mean_without': without_feature.mean(),\n",
    "            'difference': mean_diff,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05,\n",
    "            't_statistic': t_stat,\n",
    "            'expected_direction': expected_direction,\n",
    "            'actual_direction': \"positive\" if mean_diff > 0 else \"negative\",\n",
    "            'direction_confirmed': direction_confirmed,\n",
    "            'hypothesis_confirmed': direction_confirmed and p_value < 0.05\n",
    "        })\n",
    "\n",
    "    # For interaction terms (simplified approach)\n",
    "    else:\n",
    "        feature_parts = feature.split(\" \")\n",
    "        if len(feature_parts) != 2:\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hypothesis': hypothesis[\"hypothesis\"],\n",
    "                'result': \"Complex interaction term - not tested\",\n",
    "                'confirmed': False\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        feature1, feature2 = feature_parts\n",
    "\n",
    "        # Check if features exist\n",
    "        if feature1 not in df_confirm.columns or feature2 not in df_confirm.columns:\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hypothesis': hypothesis[\"hypothesis\"],\n",
    "                'result': \"One or more features not found in dataset\",\n",
    "                'confirmed': False\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Create groups for interaction\n",
    "        both_present = df_confirm[(df_confirm[feature1] == 1) & (df_confirm[feature2] == 1)][\"y\"]\n",
    "        not_both = df_confirm[~((df_confirm[feature1] == 1) & (df_confirm[feature2] == 1))][\"y\"]\n",
    "\n",
    "        # Skip if either group is too small\n",
    "        if len(both_present) < 10 or len(not_both) < 10:\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'hypothesis': hypothesis[\"hypothesis\"],\n",
    "                'result': f\"Insufficient data (both={len(both_present)}, not_both={len(not_both)})\",\n",
    "                'confirmed': False\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Perform t-test\n",
    "        t_stat, p_value = stats.ttest_ind(both_present, not_both, equal_var=False)\n",
    "\n",
    "        # Check direction\n",
    "        mean_diff = both_present.mean() - not_both.mean()\n",
    "        direction_confirmed = (\n",
    "            (expected_direction == \"positive\" and mean_diff > 0) or\n",
    "            (expected_direction == \"negative\" and mean_diff < 0)\n",
    "        )\n",
    "\n",
    "        # Record results\n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'hypothesis': hypothesis[\"hypothesis\"],\n",
    "            'mean_both': both_present.mean(),\n",
    "            'mean_not_both': not_both.mean(),\n",
    "            'difference': mean_diff,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05,\n",
    "            't_statistic': t_stat,\n",
    "            'expected_direction': expected_direction,\n",
    "            'actual_direction': \"positive\" if mean_diff > 0 else \"negative\",\n",
    "            'direction_confirmed': direction_confirmed,\n",
    "            'hypothesis_confirmed': direction_confirmed and p_value < 0.05\n",
    "        })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7GQQCOkMtiM",
    "outputId": "3ba9dc6f-8740-4b66-ee69-d25d8e303b7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWODFw-8d4wM",
    "outputId": "8929cef4-3be2-4b87-f348-ba454ae786aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Summary: 4 out of 10 hypotheses confirmed (40.0%)\n",
      "\n",
      "Confirmed Hypotheses:\n",
      "- Videos with 'self_ref' increase engagement (p=0.0005)\n",
      "  Mean with self_ref: 0.0581\n",
      "  Mean without self_ref: 0.0544\n",
      "  Difference: 0.0037\n",
      "- Videos with 'prime_hour' increase engagement (p=0.0007)\n",
      "  Mean with prime_hour: 0.0581\n",
      "  Mean without prime_hour: 0.0545\n",
      "  Difference: 0.0036\n",
      "- Videos with 'hashtag_indicator' decrease engagement (p=0.0001)\n",
      "  Mean with hashtag_indicator: 0.0527\n",
      "  Mean without hashtag_indicator: 0.0584\n",
      "  Difference: -0.0057\n",
      "- Videos with 'popular_brand' decrease engagement (p=0.0000)\n",
      "  Mean with popular_brand: 0.0489\n",
      "  Mean without popular_brand: 0.0575\n",
      "  Difference: -0.0087\n",
      "\n",
      "Unconfirmed Hypotheses:\n",
      "- Videos with 'skills/teach' increase engagement (p=0.0637)\n",
      "- Videos that combine 'popular_brand' and 'hashtag_indicator' decrease engagement (p=0.2639)\n",
      "- Videos that combine 'skills/teach' and 'hashtag_indicator' decrease engagement (p=0.5387)\n",
      "- Videos that combine 'self_ref' and 'speed' decrease engagement (p=0.2429)\n",
      "- Videos that combine 'product' and 'hashtag_indicator' increase engagement (p=0.0004)\n",
      "- Videos that combine 'popular_brand' and 'skills/teach' increase engagement (p=0.4878)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "confirmed_hypotheses = results_df[results_df['hypothesis_confirmed'] == True]\n",
    "confirmation_rate = len(confirmed_hypotheses) / len(results_df) * 100\n",
    "\n",
    "print(f\"\\nResults Summary: {len(confirmed_hypotheses)} out of {len(results_df)} hypotheses confirmed ({confirmation_rate:.1f}%)\")\n",
    "\n",
    "# confirmed hypotheses\n",
    "print(\"\\nConfirmed Hypotheses:\")\n",
    "for i, row in confirmed_hypotheses.iterrows():\n",
    "    if 'mean_with' in row:\n",
    "        print(f\"- {row['hypothesis']} (p={row['p_value']:.4f})\")\n",
    "        print(f\"  Mean with {row['feature']}: {row['mean_with']:.4f}\")\n",
    "        print(f\"  Mean without {row['feature']}: {row['mean_without']:.4f}\")\n",
    "        print(f\"  Difference: {row['difference']:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {row['hypothesis']} (p={row['p_value']:.4f})\")\n",
    "        print(f\"  Mean with both features: {row['mean_both']:.4f}\")\n",
    "        print(f\"  Mean without both features: {row['mean_not_both']:.4f}\")\n",
    "        print(f\"  Difference: {row['difference']:.4f}\")\n",
    "# unconfirmed hypotheses\n",
    "unconfirmed = results_df[results_df['hypothesis_confirmed'] != True]\n",
    "print(\"\\nUnconfirmed Hypotheses:\")\n",
    "\n",
    "for i, row in unconfirmed.iterrows():\n",
    "    if 'p_value' in row and row['p_value'] is not None:\n",
    "        print(f\"- {row['hypothesis']} (p={row['p_value']:.4f})\")\n",
    "    else:\n",
    "        print(f\"- {row['hypothesis']} (Reason: {row['result']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "v7Am1VHBd40L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3918    1\n",
       "5365    0\n",
       "4720    1\n",
       "4549    6\n",
       "6274    5\n",
       "3980    5\n",
       "903     0\n",
       "2309    0\n",
       "6448    0\n",
       "2818    1\n",
       "Name: hashtag_indicator, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"hashtag_indicator\"].sample(10)\n",
    "\n",
    "#As you can see hashtag_indicator is not a categorical variable. \n",
    "#We will disregard results about it when it comes to the above analysis as we misunderstood\n",
    "#The rest of the results about which categories contribute to the linear model we will still use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
