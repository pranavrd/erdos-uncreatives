{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e37523-42d1-466e-8490-cb4b6931b933",
   "metadata": {},
   "source": [
    "In this notebook, we will create and compare several models. Our target feature for this notebooks is LOG(VIEWS/SUBSCRIBERS))\n",
    "\n",
    "Please note that we are not really creating a \"model\" of our data. That is, we do not believe our data is fully explained by our features nor that there is underlying \"true\" relationship that is linear. We are not using linear regression to predict the data or model the data. Instead, we are finding the line of best fit and using it as an indication of trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6540735a-9ca7-4f9f-bb48-b0e2bb6d189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0',\n",
       "       'channelDescription', 'channelJoinedDate', 'channelTotalVideos',\n",
       "       'channelTotalViews', 'channelUsername', 'commentsCount', 'date',\n",
       "       'duration', 'id', 'isChannelVerified', 'likes', 'numberOfSubscribers',\n",
       "       'order', 'text', 'title', 'url', 'viewCount', 'likes_per_subscriber',\n",
       "       'comments_per_subscriber', 'views_per_subscriber',\n",
       "       'duration_in_seconds', 'datetime_date', 'hashtags', 'comm_to_views',\n",
       "       'likes_to_views', 'popular_brand', 'has_title_affiliate',\n",
       "       'has_description_affiliate', 'has_channel_description_affiliate',\n",
       "       'has_any_affiliate', 'has_business_inquiry',\n",
       "       'engagement_per_subscriber', 'product', 'budget', 'self_ref', 'acronym',\n",
       "       'korean', 'speed', 'skills/teach', 'skincare', 'comparing_products',\n",
       "       'datetime', 'hour', 'day_of_week', 'month', 'year', 'day_name',\n",
       "       'engagement_rate', 'prime_time', 'cluster1', 'prime_time1',\n",
       "       'posting_time_category', 'prime_hour', 'hasAdinTitle', 'hasAdinText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "df = pd.read_csv(r\"no_early_dates_90_days.csv\")\n",
    "df.columns\n",
    "\n",
    "#PLEASE NOTE THAT THE HASHTAGS COLUMN CURRENTLY HAS THE NUMBER OF HASHTAGS USED, AND IS NOT A CATEGORICAL VARIABLE. \n",
    "#WHEN CONSIDERING INTERACTION TERMS PLEASE ONLY INCLUDE PAIRWISE INTERACTION TERMS. More interaction terms than this would create extremely small and nonexistent categories which we do not want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7c69868-7f1b-4f87-99df-50c03fc443bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this cell more than once\n",
    "\n",
    "features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \n",
    "            \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hashtags\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "\n",
    "#Create the target column $y$ here:\n",
    "df[\"y\"] = df[\"views_per_subscriber\"].apply( math.log )\n",
    "\n",
    "#We don't need a lot of the noise columns\n",
    "df = df[ features + [\"y\"] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "174ee18d-50d9-4f5d-b30b-a78281db3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2dff4f7-65bd-4f28-abfc-833d304078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do an 80-20 Train Test Split Here. Never ever touch the testing set please!\n",
    "cat_features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "#The above is just everything except \"hashtags\"\n",
    "\n",
    "df_train, df_test = train_test_split(df, shuffle = True, test_size = .2, random_state = 42) #We can't stratify because we have too many categorical features. I hope this is ok\n",
    "#DO NOT TOUCH THE ABOVE X_TEST VARIABLE FOR ANY REASON\n",
    "\n",
    "#We want a very basic idea of the MSE for each model, before we do proper cross-validation. We use a secondary split for this.\n",
    "df_tt, df_ho = train_test_split(df_train, shuffle = True, test_size = .2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6428dbc1-d78e-47bb-9159-b42eea6a20d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1.644687\n",
      "R-squared: -0.0044\n"
     ]
    }
   ],
   "source": [
    "#Create the baseline model here\n",
    "\n",
    "class BaseMeanModel():\n",
    "    def __init__(self):\n",
    "        self.mean_value = None\n",
    "    \n",
    "    def fit(self, values : pd.Series):\n",
    "        self.mean_value = values.mean()\n",
    "\n",
    "    def predict(self, inputs=None):\n",
    "        if inputs is None:\n",
    "            return self.mean_value\n",
    "        return len(inputs) * [self.mean_value]\n",
    "    \n",
    "model = BaseMeanModel()\n",
    "model.fit(df_tt[\"y\"])\n",
    "\n",
    "# R2 is negative because training set and the hold out set have different average values\n",
    "y_pred = model.predict(df_ho[features])\n",
    "rmse = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "print(f\"Root Mean Squared Error: {rmse:.6f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a9c1ca4-fcb4-4c9c-a0f4-5e8990aab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (Log Views): 1.538600\n",
      "R-squared: 0.1210\n"
     ]
    }
   ],
   "source": [
    "#Create the basic linear regression model here \n",
    "model = LinearRegression()\n",
    "model.fit(df_tt[features], df_tt[\"y\"])\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(df_ho[features])\n",
    "rmse = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "print(f\"Root Mean Squared Error (Log Views): {rmse:.6f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d31581e-3aa9-4b52-b749-9993cf3299f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha: 0.0001\n",
      "Test MSE: 2.367330, RMSE: 1.538613, MAE: 1.188627\n",
      "R² Score: 0.120950, Explained Variance: 0.126585\n"
     ]
    }
   ],
   "source": [
    "#Create the basic linear regression model here with lasso regression. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_tt[features] )\n",
    "X_test_scaled = scaler.transform( df_ho[features])\n",
    "\n",
    "\n",
    "alpha = 0.0001\n",
    "\n",
    "lasso = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "\n",
    "\n",
    "lasso.fit(X_train_scaled, df_tt[\"y\"])\n",
    "\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(df_ho[\"y\"] ,y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "exp_var = explained_variance_score(df_ho[\"y\"], y_pred)\n",
    "\n",
    "print(f\"\\nAlpha: {alpha}\")\n",
    "print(f\"Test MSE: {mse:.6f}, RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}, Explained Variance: {exp_var:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28f85933-593b-4710-844a-0a1c7bc5436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2.356489, RMSE: 1.535086, MAE: 1.175820\n",
      "R² Score: 0.124976, Explained Variance: 0.130502\n"
     ]
    }
   ],
   "source": [
    "#Create a model whose features include all interaction terms \n",
    "pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"linear model\", LinearRegression())\n",
    "]) \n",
    "#setting degree = 2 creates all pairwise interaction terms. \n",
    "\n",
    "pipe.fit( df_tt[features], df_tt[\"y\"]) \n",
    "pred = pipe.predict( df_ho[features] )\n",
    "\n",
    "mse = mean_squared_error(df_ho[\"y\"], pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(df_ho[\"y\"], pred)\n",
    "r2 = r2_score(df_ho[\"y\"], pred)\n",
    "exp_var = explained_variance_score(df_ho[\"y\"], pred)\n",
    "\n",
    "\n",
    "print(f\"Test MSE: {mse:.6f}, RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}, Explained Variance: {exp_var:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b12a5133-9cea-407b-b0db-d0b9503d0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  1.5349475471917438\n"
     ]
    }
   ],
   "source": [
    "#Create a model with all interaction terms and lasso regression \n",
    "\n",
    "#Create a model with all interaction terms and lasso regression \n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_df_tt = scaler.fit_transform( df_tt[features] )\n",
    "scaled_df_ho = scaler.transform( df_ho[features] )\n",
    "\n",
    "# using lasso cv to find the best alpha\n",
    "# lasso = LassoCV(cv=5, random_state=42, max_iter=10000, alphas=np.logspace(-4, 1, 30))\n",
    "# lasso.fit(df_tt[features], df_tt[\"y\"])\n",
    "# pred = lasso.predict(df_ho[features])\n",
    "# print(\"Lasso CV MSE:\", root_mean_squared_error(df_ho[\"y\"], pred))\n",
    "# print(\"Optimal alpha:\", lasso.alpha_)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"interaction terms\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "])\n",
    "pipe.fit(scaled_df_tt, df_tt[\"y\"])\n",
    "pred = pipe.predict(scaled_df_ho)\n",
    "print(\"MSE : \", root_mean_squared_error(df_ho[\"y\"], pred))\n",
    "\n",
    "# Get lasso coefficients\n",
    "lasso_coeffs = pd.Series(pipe.named_steps['lasso'].coef_, index=pipe.named_steps['interaction terms'].get_feature_names_out(features))\n",
    "lasso_coeffs = lasso_coeffs[lasso_coeffs != 0]\n",
    "# print(lasso_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a48034c-5135-4a52-a6f3-57bb5d03c11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.64468734 1.57164797 1.56909547 1.64753598 1.70829604]\n",
      " [1.53860029 1.48638939 1.49762178 1.56249385 1.63738036]\n",
      " [1.53861317 1.48638776 1.49760963 1.562494   1.63735979]\n",
      " [1.53508614 1.45829658 1.48308619 1.55340947 1.68253152]\n",
      " [1.53494755 1.45822724 1.48293006 1.55322598 1.68145669]]\n"
     ]
    }
   ],
   "source": [
    "#Do cross-validation to compare all models \n",
    "\n",
    "#Model 0: Baseline Average\n",
    "#Model 1: Basic Linear Regression Model\n",
    "#Model 2: Linear Regression with Lasso\n",
    "#Model 3: Linear Regression with interaction terms\n",
    "#Model 4: Linear Regression with interactions and lasso\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "num_splits = 5\n",
    "num_models = 5\n",
    "\n",
    "kfold = KFold(num_splits,\n",
    "              random_state = 42,\n",
    "              shuffle=True)\n",
    "\n",
    "rmses = np.zeros((num_models, num_splits))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df_train)): \n",
    "\n",
    "    df_tt = df_train.iloc[train_index]\n",
    "    df_ho = df_train.iloc[test_index] \n",
    "\n",
    "    #Model 0: Baseline Average\n",
    "    model = BaseMeanModel()\n",
    "    model.fit(df_tt[\"y\"])\n",
    "    y_pred = model.predict(df_ho[features])\n",
    "    rmses[0,i] = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "\n",
    "    #Model 1: Basic Linear Regression Model\n",
    "    model = LinearRegression()\n",
    "    model.fit(df_tt[features], df_tt[\"y\"])\n",
    "    y_pred = model.predict(df_ho[features])\n",
    "    rmses[1,i] = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "\n",
    "    #Model 2: Linear Regression with Lasso\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(df_tt[features] )\n",
    "    X_test_scaled = scaler.transform( df_ho[features])\n",
    "    alpha = 0.0001\n",
    "    lasso = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, df_tt[\"y\"])\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "    rmses[2,i] = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "\n",
    "    #Model 3: Linear Regression with interaction terms\n",
    "    pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"linear model\", LinearRegression())\n",
    "                    ]) \n",
    "    pipe.fit( df_tt[features], df_tt[\"y\"]) \n",
    "    y_pred = pipe.predict( df_ho[features] )\n",
    "    rmses[3,i] = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "\n",
    "    #Model 4: Linear Regression with interactions and lasso\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df_tt = scaler.fit_transform( df_tt[features] )\n",
    "    scaled_df_ho = scaler.transform( df_ho[features] )\n",
    "    pipe = Pipeline([\n",
    "    (\"interaction terms\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "                    ])\n",
    "    pipe.fit(scaled_df_tt, df_tt[\"y\"])\n",
    "    y_pred = pipe.predict(scaled_df_ho)\n",
    "    rmses[4,i] = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "\n",
    "print(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcd3249e-7178-409f-95c0-f0fcca1fa21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62825256, 1.54449714, 1.54449287, 1.54248198, 1.5421575 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90674a6-d45c-4c46-979f-d08de1620da6",
   "metadata": {},
   "source": [
    "#Final interpretation. We'll look at coefficients for our best model and compare. \n",
    "\n",
    "---Final Interpretation---\n",
    "\n",
    "Almost as expected, the model with the most features (i.e., the model that includes all interaction terms) performed the best. This is this could just be because every time a linear model has more features it will perform better, in the sense that it will have a lower rmse. \n",
    "\n",
    "Interestingly, our lasso model slightly outperformed our non-lasso model. \n",
    "\n",
    "We want to take the coefficients of our highest performing model and compare them. This is where our analysis was really headed.\n",
    "Mathematically, the features with the highest coefficients are those that contribute the most to the trend line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66079140-9136-4386-9b0b-2f90b5746a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular_brand               0.097420\n",
      "has_any_affiliate          -0.119768\n",
      "product                     0.134183\n",
      "budget                      0.088134\n",
      "self_ref                    0.022883\n",
      "                              ...   \n",
      "prime_hour hasAdinTitle    -0.002207\n",
      "prime_hour hasAdinText      0.016012\n",
      "hashtags hasAdinTitle       0.099113\n",
      "hashtags hasAdinText       -0.010577\n",
      "hasAdinTitle hasAdinText   -0.075326\n",
      "Length: 120, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A final fitting to the whole data set \n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform( df[features] )\n",
    "pipe = Pipeline([\n",
    "    (\"interaction terms\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "                    ])\n",
    "pipe.fit(scaled_df, df[\"y\"])\n",
    "\n",
    "lasso_coeffs = pd.Series(pipe.named_steps['lasso'].coef_, index=pipe.named_steps['interaction terms'].get_feature_names_out(features))\n",
    "sig_lasso_coeffs = lasso_coeffs[lasso_coeffs != 0]\n",
    "print(sig_lasso_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "861bc90d-63d0-4f13-80cd-f8143db619a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acronym hasAdinTitle               0.000234\n",
       "skincare comparing_products       -0.000679\n",
       "product speed                     -0.001106\n",
       "skills/teach comparing_products   -0.002053\n",
       "prime_hour hasAdinTitle           -0.002207\n",
       "                                     ...   \n",
       "acronym                            0.154045\n",
       "has_any_affiliate hashtags         0.219883\n",
       "hashtags                           0.223845\n",
       "acronym hashtags                   0.250303\n",
       "korean                             0.261197\n",
       "Length: 120, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_lasso_coeffs.sort_values(key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7adeb2ca-5146-40bf-aae1-94b492af799d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasAdinText                  -0.104489\n",
       "has_any_affiliate speed       0.107565\n",
       "has_any_affiliate            -0.119768\n",
       "product                       0.134183\n",
       "self_ref hashtags             0.147005\n",
       "acronym                       0.154045\n",
       "has_any_affiliate hashtags    0.219883\n",
       "hashtags                      0.223845\n",
       "acronym hashtags              0.250303\n",
       "korean                        0.261197\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = sig_lasso_coeffs.sort_values(key=abs)\n",
    "new.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c996d0-a175-43db-90ce-b9fa3650814a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
