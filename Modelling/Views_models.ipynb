{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e37523-42d1-466e-8490-cb4b6931b933",
   "metadata": {},
   "source": [
    "# In this notebook, we will create and compare several models. Our target feature for this notebooks is LOG(VIEWS/SUBSCRIBERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6540735a-9ca7-4f9f-bb48-b0e2bb6d189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0',\n",
       "       'channelDescription', 'channelJoinedDate', 'channelTotalVideos',\n",
       "       'channelTotalViews', 'channelUsername', 'commentsCount', 'date',\n",
       "       'duration', 'id', 'isChannelVerified', 'likes', 'numberOfSubscribers',\n",
       "       'order', 'text', 'title', 'url', 'viewCount', 'likes_per_subscriber',\n",
       "       'comments_per_subscriber', 'views_per_subscriber',\n",
       "       'duration_in_seconds', 'datetime_date', 'hashtags', 'comm_to_views',\n",
       "       'likes_to_views', 'popular_brand', 'has_title_affiliate',\n",
       "       'has_description_affiliate', 'has_channel_description_affiliate',\n",
       "       'has_any_affiliate', 'has_business_inquiry',\n",
       "       'engagement_per_subscriber', 'product', 'budget', 'self_ref', 'acronym',\n",
       "       'korean', 'speed', 'skills/teach', 'skincare', 'comparing_products',\n",
       "       'datetime', 'hour', 'day_of_week', 'month', 'year', 'day_name',\n",
       "       'engagement_rate', 'prime_time', 'cluster1', 'prime_time1',\n",
       "       'posting_time_category', 'prime_hour', 'hasAdinTitle', 'hasAdinText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "df = pd.read_csv(r\"no_early_dates_90_days.csv\")\n",
    "df.columns\n",
    "\n",
    "#PLEASE NOTE THAT THE HASHTAGS COLUMN CURRENTLY HAS THE NUMBER OF HASHTAGS USED, AND IS NOT A CATEGORICAL VARIABLE. \n",
    "#WHEN CONSIDERING INTERACTION TERMS PLEASE ONLY INCLUDE PAIRWISE INTERACTION TERMS. More interaction terms than this would create extremely small and nonexistent categories which we do not want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c69868-7f1b-4f87-99df-50c03fc443bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this cell more than once\n",
    "\n",
    "features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hashtags\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "\n",
    "#Create the target column $y$ here:\n",
    "df[\"y\"] = df[\"views_per_subscriber\"].apply( math.log )\n",
    "\n",
    "#We don't need a lot of the noise columns\n",
    "df = df[ features + [\"y\"] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174ee18d-50d9-4f5d-b30b-a78281db3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2dff4f7-65bd-4f28-abfc-833d304078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do an 80-20 Train Test Split Here. Never ever touch the testing set please!\n",
    "cat_features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "#The above is just everything except \"hashtags\"\n",
    "\n",
    "df_train, df_test = train_test_split(df, shuffle = True, test_size = .2) #We can't stratify because we have too many categorical features. I hope this is ok\n",
    "#DO NOT TOUCH THE ABOVE X_TEST VARIABLE FOR ANY REASON\n",
    "\n",
    "#We want a very basic idea of the MSE for each model, before we do proper cross-validation. We use a secondary split for this.\n",
    "df_tt, df_ho = train_test_split(df_train, shuffle = True, test_size = .2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6428dbc1-d78e-47bb-9159-b42eea6a20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the baseline model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c1ca4-fcb4-4c9c-a0f4-5e8990aab033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat the basic linear regression model here \n",
    "model = LinearRegression()\n",
    "model.fit(df_tt[features], df_tt[\"y\"])\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(df_ho[features])\n",
    "rmse = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "print(f\"Root Mean Squared Error (Log Views): {rmse:.6f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d31581e-3aa9-4b52-b749-9993cf3299f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the basic linear regression model here with lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f85933-593b-4710-844a-0a1c7bc5436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5101863989903899\n"
     ]
    }
   ],
   "source": [
    "#Create a model whose features include all interaction terms \n",
    "pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"linear model\", LinearRegression())\n",
    "]) \n",
    "#setting degree = 2 creates all pairwise interaction terms. \n",
    "\n",
    "pipe.fit( df_tt[features], df_tt[\"y\"]) \n",
    "pred = pipe.predict( df_ho[features] )\n",
    "\n",
    "print( root_mean_squared_error( df_ho[\"y\"], pred) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12a5133-9cea-407b-b0db-d0b9503d0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  1.510058726098824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_tt[features] = scaler.fit_transform(df_tt[features])\n",
    "df_ho[features] = scaler.transform(df_ho[features])\n",
    "\n",
    "#Create a model whose features include all interaction terms and a lasso regression\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # using lasso cv to find the best alpha\n",
    "# lasso = LassoCV(cv=5, random_state=42, max_iter=10000, alphas=np.logspace(-4, 1, 30))\n",
    "# lasso.fit( df_tt[features], df_tt[\"y\"])\n",
    "# pred = lasso.predict( df_ho[features] )\n",
    "# print(\"Lasso CV MSE : \",root_mean_squared_error( df_ho[\"y\"], pred) )\n",
    "# print(\"Optimal Alpha : \", lasso.alpha_ )\n",
    "\n",
    "\n",
    "pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"lasso\", Lasso(alpha=0.0001, max_iter=10000))\n",
    "])\n",
    "pipe.fit( df_tt[features], df_tt[\"y\"])\n",
    "pred = pipe.predict( df_ho[features] )\n",
    "print(\"MSE : \",root_mean_squared_error( df_ho[\"y\"], pred) )\n",
    "\n",
    "# Get lasso coefficients\n",
    "lasso_coef = pd.Series(pipe.named_steps['lasso'].coef_, index=pipe.named_steps['interaction terms'].get_feature_names_out(features))\n",
    "lasso_coef = lasso_coef[lasso_coef != 0]\n",
    "# print(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a48034c-5135-4a52-a6f3-57bb5d03c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do cross-validation to compare all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e385db-e0eb-4064-8ade-eb7c7ebd404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final interpretation. We'll look at coefficients for our best model and compare. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
