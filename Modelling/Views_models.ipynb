{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e37523-42d1-466e-8490-cb4b6931b933",
   "metadata": {},
   "source": [
    "# In this notebook, we will create and compare several models. Our target feature for this notebooks is LOG(VIEWS/SUBSCRIBERS))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 1,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "6540735a-9ca7-4f9f-bb48-b0e2bb6d189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0',\n",
       "       'channelDescription', 'channelJoinedDate', 'channelTotalVideos',\n",
       "       'channelTotalViews', 'channelUsername', 'commentsCount', 'date',\n",
       "       'duration', 'id', 'isChannelVerified', 'likes', 'numberOfSubscribers',\n",
       "       'order', 'text', 'title', 'url', 'viewCount', 'likes_per_subscriber',\n",
       "       'comments_per_subscriber', 'views_per_subscriber',\n",
       "       'duration_in_seconds', 'datetime_date', 'hashtags', 'comm_to_views',\n",
       "       'likes_to_views', 'popular_brand', 'has_title_affiliate',\n",
       "       'has_description_affiliate', 'has_channel_description_affiliate',\n",
       "       'has_any_affiliate', 'has_business_inquiry',\n",
       "       'engagement_per_subscriber', 'product', 'budget', 'self_ref', 'acronym',\n",
       "       'korean', 'speed', 'skills/teach', 'skincare', 'comparing_products',\n",
       "       'datetime', 'hour', 'day_of_week', 'month', 'year', 'day_name',\n",
       "       'engagement_rate', 'prime_time', 'cluster1', 'prime_time1',\n",
       "       'posting_time_category', 'prime_hour', 'hasAdinTitle', 'hasAdinText'],\n",
       "      dtype='object')"
      ]
     },
<<<<<<< HEAD
     "execution_count": 26,
=======
     "execution_count": 1,
>>>>>>> 8303918 (lasso with best alpha)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "df = pd.read_csv(r\"no_early_dates_90_days.csv\")\n",
    "df.columns\n",
    "\n",
    "#PLEASE NOTE THAT THE HASHTAGS COLUMN CURRENTLY HAS THE NUMBER OF HASHTAGS USED, AND IS NOT A CATEGORICAL VARIABLE. \n",
    "#WHEN CONSIDERING INTERACTION TERMS PLEASE ONLY INCLUDE PAIRWISE INTERACTION TERMS. More interaction terms than this would create extremely small and nonexistent categories which we do not want."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 2,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "a7c69868-7f1b-4f87-99df-50c03fc443bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this cell more than once\n",
    "\n",
    "features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hashtags\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "\n",
    "#Create the target column $y$ here:\n",
    "df[\"y\"] = df[\"views_per_subscriber\"].apply( math.log )\n",
    "\n",
    "#We don't need a lot of the noise columns\n",
    "df = df[ features + [\"y\"] ] "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 3,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "174ee18d-50d9-4f5d-b30b-a78281db3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 4,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "b2dff4f7-65bd-4f28-abfc-833d304078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do an 80-20 Train Test Split Here. Never ever touch the testing set please!\n",
    "cat_features = [\"popular_brand\", \"has_any_affiliate\", \"product\", \"budget\", \"self_ref\", \"acronym\", \"korean\", \"speed\", \"skills/teach\", \"skincare\", \"comparing_products\", \"prime_hour\", \"hasAdinTitle\", \"hasAdinText\"]\n",
    "#The above is just everything except \"hashtags\"\n",
    "\n",
    "df_train, df_test = train_test_split(df, shuffle = True, test_size = .2) #We can't stratify because we have too many categorical features. I hope this is ok\n",
    "#DO NOT TOUCH THE ABOVE X_TEST VARIABLE FOR ANY REASON\n",
    "\n",
    "#We want a very basic idea of the MSE for each model, before we do proper cross-validation. We use a secondary split for this.\n",
    "df_tt, df_ho = train_test_split(df_train, shuffle = True, test_size = .2)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 5,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "6428dbc1-d78e-47bb-9159-b42eea6a20d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1.644687\n",
      "R-squared: -0.0044\n"
     ]
    }
   ],
   "source": [
    "#Create the baseline model here\n",
    "\n",
    "class BaseMeanModel():\n",
    "    def __init__(self):\n",
    "        self.mean_value = None\n",
    "    \n",
    "    def fit(self, values : pd.Series):\n",
    "        self.mean_value = values.mean()\n",
    "\n",
    "    def predict(self, inputs=None):\n",
    "        if inputs is None:\n",
    "            return self.mean_value\n",
    "        return len(inputs) * [self.mean_value]\n",
    "    \n",
    "model = BaseMeanModel()\n",
    "model.fit(df_tt[\"y\"])\n",
    "\n",
    "# R2 is negative because training set and the hold out set have different average values\n",
    "y_pred = model.predict(df_ho[features])\n",
    "rmse = root_mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "print(f\"Root Mean Squared Error: {rmse:.6f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 6,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "7a9c1ca4-fcb4-4c9c-a0f4-5e8990aab033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat the basic linear regression model here "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 7,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "4d31581e-3aa9-4b52-b749-9993cf3299f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha: 0.0001\n",
      "Test MSE: 2.367330, RMSE: 1.538613, MAE: 1.188627\n",
      "R² Score: 0.120950, Explained Variance: 0.126585\n"
     ]
    }
   ],
   "source": [
    "#Create the basic linear regression model here with lasso regression. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_tt[features] )\n",
    "X_test_scaled = scaler.transform( df_ho[features])\n",
    "\n",
    "\n",
    "alpha = 0.0001\n",
    "\n",
    "lasso = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "\n",
    "\n",
    "lasso.fit(X_train_scaled, df_tt[\"y\"])\n",
    "\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(df_ho[\"y\"], y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(df_ho[\"y\"] ,y_pred)\n",
    "r2 = r2_score(df_ho[\"y\"], y_pred)\n",
    "exp_var = explained_variance_score(df_ho[\"y\"], y_pred)\n",
    "\n",
    "print(f\"\\nAlpha: {alpha}\")\n",
    "print(f\"Test MSE: {mse:.6f}, RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}, Explained Variance: {exp_var:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 8,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "28f85933-593b-4710-844a-0a1c7bc5436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Test MSE: 2.356489, RMSE: 1.535086, MAE: 1.175820\n",
      "R² Score: 0.124976, Explained Variance: 0.130502\n"
=======
      "1.5633785548101489\n"
>>>>>>> 8303918 (lasso with best alpha)
     ]
    }
   ],
   "source": [
    "#Create a model whose features include all interaction terms \n",
    "pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"linear model\", LinearRegression())\n",
    "]) \n",
    "#setting degree = 2 creates all pairwise interaction terms. \n",
    "\n",
    "pipe.fit( df_tt[features], df_tt[\"y\"]) \n",
    "pred = pipe.predict( df_ho[features] )\n",
    "\n",
    "mse = mean_squared_error(df_ho[\"y\"], pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(df_ho[\"y\"], pred)\n",
    "r2 = r2_score(df_ho[\"y\"], pred)\n",
    "exp_var = explained_variance_score(df_ho[\"y\"], pred)\n",
    "\n",
    "\n",
    "print(f\"Test MSE: {mse:.6f}, RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}, Explained Variance: {exp_var:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 9,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "b12a5133-9cea-407b-b0db-d0b9503d0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso CV MSE :  1.5711475982960674\n",
      "Optimal Alpha :  0.0001\n",
      "MSE :  1.5631963330645298\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#Create a model with all interaction terms and lasso regression \n",
    "\n",
    "\n"
=======
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_tt[features] = scaler.fit_transform(df_tt[features])\n",
    "df_ho[features] = scaler.transform(df_ho[features])\n",
    "\n",
    "#Create a model whose features include all interaction terms and a lasso regression\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# using lasso cv to find the best alpha\n",
    "lasso = LassoCV(cv=5, random_state=42, max_iter=10000, alphas=np.logspace(-4, 1, 30))\n",
    "lasso.fit( df_tt[features], df_tt[\"y\"])\n",
    "pred = lasso.predict( df_ho[features] )\n",
    "print(\"Lasso CV MSE : \",root_mean_squared_error( df_ho[\"y\"], pred) )\n",
    "print(\"Optimal Alpha : \", lasso.alpha_ )\n",
    "\n",
    "\n",
    "pipe = Pipeline([  (\"interaction terms\", PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False) ),\n",
    "                   (\"lasso\", Lasso(alpha=lasso.alpha_, max_iter=10000))\n",
    "])\n",
    "pipe.fit( df_tt[features], df_tt[\"y\"])\n",
    "pred = pipe.predict( df_ho[features] )\n",
    "print(\"MSE : \",root_mean_squared_error( df_ho[\"y\"], pred) )\n",
    "\n",
    "# Get lasso coefficients\n",
    "lasso_coef = pd.Series(pipe.named_steps['lasso'].coef_, index=pipe.named_steps['interaction terms'].get_feature_names_out(features))\n",
    "lasso_coef = lasso_coef[lasso_coef != 0]\n",
    "# print(lasso_coef)"
>>>>>>> 8303918 (lasso with best alpha)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 10,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "4a48034c-5135-4a52-a6f3-57bb5d03c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do cross-validation to compare all models "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 11,
>>>>>>> 8303918 (lasso with best alpha)
   "id": "36e385db-e0eb-4064-8ade-eb7c7ebd404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final interpretation. We'll look at coefficients for our best model and compare. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3 (ipykernel)",
=======
   "display_name": "erdos_spring_2025",
>>>>>>> 8303918 (lasso with best alpha)
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
